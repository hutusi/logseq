- AIGC下的组织高效运作： #QCon
	- 高效组织的经验（乔新亮）：
		- 1、制定远大的目标
		- 2、领导力
		- 3、复盘，持续改进，持续学习，持续成长
		- 4、鼓励犯错，容错、试错的文化
		- 5、做大蛋糕（业务成功），切好蛋糕（公平公正）
	- 组织变革的那些坑（袁店明）：
		- 1、测试焦油坑：质量最后由测试兜底
		- 2、三个和尚没水吃：部门山头林立，责任互相推诿
		- 3、都是干部，干活的只有一个，组织层级多
		- 4、船长弃船逃跑
	- 数字化研发组织的演进（张燎原）：
		- 研发组织的演进：1、职能团队：按职能分工，各管一段；2、跨职能特性团队：以跨职能团队方式组织研发队伍，能力共享；并且建立虚拟的SQA团队进入产品线，负责流程改进。3、工具平台化、效能改进专业化、安全生产常态化：建立横向工具团队，服务整个集团，走平台工程的道路，逐步形成工具平台产品线，辅以专业化效能改进服务；以市场化的方式服务于内部。（带来的问题：团队规模变大，工具平台、安全生产等部门成本逐步上升。）
		- 阿里的DevOps工具平台工程建设之路：2009~2013：单点的自动化发布工具；2013~2016：统一构建部署平台；2016~2017：DevOps平台，从需求到代码，从交付到反馈的一站式平台；2017~2019：全面自研上云，推出阿里云上研发平台，赋能开发者；2019~：下一代研发平台，开放、标准、普惠。
		- 过程中遇到的问题：
			- 技术侧：巨型应用导致协作成本飙升，“瀑布式”研发模式降低交付效率，模块多导致出问题影响大。因此做微服务化改造，但也引入了新的问题，比如：服务变多导致运维出现瓶颈、链路长问题排查困难等。
			- 业务侧：业务团队各搞一套重复建设，业务模型不一致数据不一致，核心交易逻辑出现差异。因此搞中台建设：大中台、小前台。也引入了中台的问题：中台逻辑业务逻辑迭代不一致、各子业务代码互相影响、小业务无法得到有效保障、中台逻辑累计再变成巨型应用。
		- 因此阿里推行数字化研发组织，统一、连接软件研发活动。以Dev视角为中心，将应用串联整个DevOps工具链。以应用为视角，进行软件的部署和运维。建立数字化需求管理流程。基于价值流，构建产研数字化体系。
-
- 从MLOps到LLMOps： #QCon
	- 人工智能发展路径：
		- 人工智能 --> 机器学习（计算机通过算法，利用经验（数据）来改善系统自身的性能）--> 深度学习（一种实现机器学习的技术，利用深度神经网络，实现层级特征抽象和表示学习）
		- 大模型（Foundation Model，参数在十亿以上的神经网络模型，通常以Transformer作为基础结构，在海量无标注数据上进行自监督学习） --> 大语言模型（Large Language Model，一种具备对语言的理解和生成能力的大模型；基于Transformer的注意力机制，通过SFT激发后出现涌现能力）
	- MLOps：机器学习时代的DevOps，建立标准化的模型开发、训练、部署、上线、监控的最佳实践
		- 遇到的问题是什么：数据和模型缺乏统一的管理，模型开发训练部署周期长……
		- 关键技术：
			- 自动化数据标注：自动化进行数据标注，去除噪声数据，保证模型训练数据的质量
			- 版本控制：使用Git版本管理算法代码、数据、模型等文件
			- AutoML+AutoDL：使用AutoML等技术自动搜索算法和调参，找到最佳模型，缩短训练周期
			- 可解释性：通过可解释性来分析模型行为，提高模型透明度
			- 漂移监控：收集模型训练和推理日志，设定关键指标，监控模型性能，实现自动重训
			- 模型适配：持续扩展模型适配的硬件范围，促成广泛环境下的模型自动部署
			- 模型压缩：使用剪枝、量化等技术来压缩模型大小，降低部署成本
			- API-Centric：平台主要操作行为可代码化，可自动执行
		- LLMOps的关键挑战和关键技术：
			- 大模型推理性能优化：
				- 大模型量化：将神经网络的浮点算法换换为定点，从而降低模型权重数值的存储空间
				- 大模型稀疏：另一个模型压缩的有效手段就是稀疏压缩。其核心是将模型中的矩阵参数压缩成适合硬件架构的格式
			- Prompt构建和自动优化：
				- Prompt的质量很大程度上决定了LLM的输出结果
				- 提示工程实践：提前预设效果最佳的Prompt模板。有：零样本提示，小样本提示，思维连提示（CoT），生成知识提示。
				- 自动化提示工程：通过模型自动构建最佳Prompt。有两种方法，一种是训练一个专用的模型来优化Prompt；另一种是建立自动提升工程优化链（APO Automatic Prompt Optimization），原始Prompt --> 调用LLM输出结果 --> 对结果不满意，自动分析结果不正确的原因 --> 自动优化Prompt提供多个选项--> 自动评估Prompt并建议改写原Prompt --> 再次输入并调用LLM，以此循环，直到获得满意的结果。
			- 上下文长度扩展：
				- 当前很多大模型对输入限制在2K左右的Token，对实际应用造成局限。
				- 通过LangChain来扩展输入的上下文长度
				- 另一种扩展方式是 NBCE
		- 未来展望和技术趋势：
			- 基础大模型不再稀缺：越来越多的高质量开源模型将充斥市场；缺乏特色的开源模型将快速退出市场；市场焦点会转移到新一代大模型竞争上（多模态、更加智能……）
			- 行业大模型短期内将涌现：具备行业特色的行业大模型将大规模出现；超强的基础大模型出现后，将抑制行业大模型的发展；行业数据价值会缩减，但可以用于新一代基础大模型调优或外挂数据库。
			- LLMOps工具将更加重要：伴随着行业大模型的兴起，LLMOps工具将变得重要；虽然基础大模型的能力增强会抑制行业大模型，但LLMOps仍将在基础大模型的应用快速落地和降低成本方便发挥作用。
-
- AIGC下的研发效能提升 #QCon
	- DevChat：从实践来到实践中去的GPT智能编程工具设计（胡涛）
		- 智能编程助手，选Copilot还是ChatGPT？
			- Copilot：自动补全建议，根据注释生成代码，根据代码生成注释，注释补全，代码补全；Tab……Tab……一行行、一段段补全
			- ChatGPT：理解自然语言，根据需求描述，生成大段代码
			- Copilot是副驾驶；ChatGPT是要当驾驶员
			- Copilot + ChatGPT = Copilot Chat
		- Copilot Chat 表现如何？
			- 可以解释代码、基于打开的文件作为上下文回到问题、分析软件需求等……
			- 但不可以灵活管理自动以的Prompt模板，不能灵活选择代码片段上下文进行提问
		- 思考：精准的上下文 + 合适的Prompt = GPT输出满意的答案
		- DevChat：
			- 上下文足够灵活、透明、准确
			- 和选中的代码块精确Diff
			- 非代码类的上下文支持
			- 内置Prompt模板
			- 灵活自定义你自己的Prompt模板
		- GPT-4在软件开发过程中的能力边界在哪里？
			- 1、辅助技能提升
			- 2、综合“技术选型”
			- 3、快速生成Terraform配置
			- 4、生成简单的Python脚本
			- 5、构造复杂的Bug复现场景
		- 在GPT-4的帮助下从0到1写一个开源项目
			- 1、需求分析
			- 2、接口设计
			- 3、代码编写
			- 4、单元测试生成
			- 5、双语文档
			- 6、代码重构
			- 7、CI配置
			- 8、开源协议等
			- 9、Code Review
			- 10、Commit Message
			- 11、Bugfix……
		- 在未来的软件开发中：GPT将成为写代码的主力，而人将成为任务组织者、过程指导者和结果验证者
			-
- “不闻不若闻之，闻之不若见之，见之不若知之，知之不若行之。”——荀子《儒效篇》 #quote
- What I cannot create, I cannot understand. —— 费曼(Richard Feynman) #quote
-
- 深度学习入门：基于Python的理论与实现 #人工智能
	- 一维数组：向量；二维数组：矩阵；三维及以上数组：张量
	- 感知机：
		- 1957年由罗森布拉特(Frank Rosenblatt)提出。
		- 定义：接收多个输入信号(x)，每个信号有权重(w)，神经元计算输入信号的总和(x*w)，当总和超过设定阈值(θ)时，神经元被激活，输出1。感知机可以表示为如下数学公式：
		- ```
		  $$
		  y=
		  \begin{cases}
		  0 & \quad \text{$(w_1 \times x_1+w_2 \times x_2 \leq \theta)$}\\
		  1 & \quad \text{$(w_1 \times x_1 + w_2 \times x_2 > \theta)$}
		  \end{cases}
		  $$```
		- 可以将阈值 $\theta$ 移到公式左边换成 -b，这里的b即**偏置**:
		- ```
		  $$
		  y=
		  \begin{cases}
		  0 & \quad \text{$(b+w_1 \times x_1+w_2 \times x_2 \leq 0)$}\\
		  1 & \quad \text{$(b+w_1 \times x_1 + w_2 \times x_2 > 0)$}
		  \end{cases}
		  $$```
		- 感知机的实现：与门、与非门、或门；但感知机无法表示异或门。用线性图可以看出，无法画出分割异或门的直线。对此，解决的方案是使用两层感知机来进行组合，即多层感知机。
	- 神经网络：
		- 神经网络： 输入层 --> 中间层（隐藏层） --> 输出层
		- 对于上文中的公式，引入一个新函数h(x)来简化：$y=h(b+w_1 \times x_1 + w2 \times x_2)$ ，简化后的公式为：
		- ```
		  $$ h(x)=
		  \begin{cases}
		  0 & \quad \text{$(x \leq 0)$}\\
		  1 & \quad \text{$(x > 0)$}
		  \end{cases}
		  $$```
		- h(x) 会将输入信号的总和转换为输出信号，这种函数被称为 **激活函数**。
		- 神经网络中经常使用的一个激活函数是 sigmoid 函数(sigmoid function): $h(x)=\dfrac{1}{1+exp(-x)}$
		-
-
-
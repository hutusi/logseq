## 数学基础
	- [[神经网络的数学基础]]
- ## 感知机的数学表示
	- 定义：接收多个输入信号(x)，每个信号有权重(w)，神经元计算输入信号的总和(x*w)，当总和超过设定阈值(θ)时，神经元被激活，输出1。 ![F3B443CA-A50A-4D4B-BBAF-D1FCC40C9E98_1_102_o.jpeg](../assets/F3B443CA-A50A-4D4B-BBAF-D1FCC40C9E98_1_102_o_1697512021843_0.jpeg)
	- 感知机可以表示为如下数学公式：
	- ```
	  $$
	  y=
	  \begin{cases}
	  0 & \quad \text{$(w_1 \times x_1+w_2 \times x_2 \leq \theta)$}\\
	  1 & \quad \text{$(w_1 \times x_1 + w_2 \times x_2 > \theta)$}
	  \end{cases}
	  $$```
	- 可以将阈值 $\theta$ 移到公式左边换成 -b，这里的b即**偏置**:
	- ```
	  $$
	  y=
	  \begin{cases}
	  0 & \quad \text{$(b+w_1 \times x_1+w_2 \times x_2 \leq 0)$}\\
	  1 & \quad \text{$(b+w_1 \times x_1 + w_2 \times x_2 > 0)$}
	  \end{cases}
	  $$```
- ## 神经网络的数学表示
	- ![9DF62D96-B8F6-4986-BC22-8876BD226141_1_102_o.jpeg](../assets/9DF62D96-B8F6-4986-BC22-8876BD226141_1_102_o_1697378465470_0.jpeg)
	- 将上述感知机的公式 引入一个新函数h(x)来简化：$h(x)=h(b+w_1 \times x_1 + w2 \times x_2)$
	- 这个新函数就是激活函数：
	- ```
	  $$ h(x)=
	  \begin{cases}
	  0 & \quad \text{$(x \leq 0)$}\\
	  1 & \quad \text{$(x > 0)$}
	  \end{cases}
	  $$```
	- 神经网络中常用的两个激活函数：
		- sigmoid激活函数 $h(x)=\dfrac{1}{1+e^{-x}}$
		- ![57701AE3-A89A-48C8-83C7-45C934672C64_1_102_o.jpeg](../assets/57701AE3-A89A-48C8-83C7-45C934672C64_1_102_o_1697380114529_0.jpeg)
		- ReLU激活函数：
		- $$ h(x)=
		  \begin{cases}
		  x & \quad \text{$(x > 0)$}\\
		  0 & \quad \text{$(x \leq 0)$}
		  \end{cases}
		  $$
		- ![BA69CE85-BDC2-41BD-A1B9-4931BB05D389_1_102_o.jpeg](../assets/BA69CE85-BDC2-41BD-A1B9-4931BB05D389_1_102_o_1697380398409_0.jpeg)
-
	- 使用多维数组（张量）来表示神经网络：
-
- ## 神经网络的学习
	- ### 梯度下降算法
	- ### 反向传播算法
-